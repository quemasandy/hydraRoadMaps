# Ejercicio 17: GANs Generativos

**Objetivo:** Implementar Generative Adversarial Networks (GANs) desde cero, comprendiendo el entrenamiento adversarial entre generador y discriminador.

## ğŸ“– TeorÃ­a

### Â¿QuÃ© son las GANs?

**Dos redes neuronales compitiendo entre sÃ­ para generar datos realistas.**

**Componentes:**
- **Generador (G):** Crea datos falsos que parecen reales
- **Discriminador (D):** Distingue entre datos reales y falsos

**AnalogÃ­a: Falsificador vs Detective**

```
Generador = Falsificador de billetes
  - Intenta crear billetes que parezcan reales
  - Mejora cada vez que el detective lo detecta

Discriminador = Detective
  - Intenta distinguir billetes reales de falsos
  - Mejora cada vez que se equivoca

Resultado: Billetes falsos cada vez mÃ¡s realistas
```

### Arquitectura de una GAN

```
Proceso de GeneraciÃ³n:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ruido (z)    â”‚  Vector aleatorio
â”‚ [random vec] â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Generator (G)  â”‚  Red neuronal
â”‚   z â†’ G(z)       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Fake Data        â”‚  Imagen/datos generados
â”‚ (looks real)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Proceso de DiscriminaciÃ³n:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Real Data   â”‚     â”‚  Fake Data   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Discriminator(D)â”‚
       â”‚ x â†’ D(x)        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Real or Fake?  â”‚
       â”‚  [0.0 - 1.0]    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       0 = Fake, 1 = Real
```

### FunciÃ³n de PÃ©rdida (Loss)

**Discriminador:**
```
L_D = -E[log D(x_real)] - E[log(1 - D(G(z)))]

Objetivo: Maximizar esta funciÃ³n
- Quiere D(x_real) = 1 (reconocer reales)
- Quiere D(G(z)) = 0 (detectar falsos)
```

**Generador:**
```
L_G = -E[log D(G(z))]

Objetivo: Minimizar esta funciÃ³n
- Quiere D(G(z)) = 1 (engaÃ±ar al discriminador)
```

**MinMax Game:**
```
min_G max_D V(D,G) = E[log D(x)] + E[log(1 - D(G(z)))]

Equilibrio de Nash: Cuando ninguno puede mejorar unilateralmente
```

### Entrenamiento Adversarial

**Algoritmo paso a paso:**

```
Para cada iteraciÃ³n:

  1. Entrenar Discriminador (k pasos):
     a. Tomar batch de datos reales: x ~ p_data
     b. Generar batch de datos falsos: z ~ p_z, x_fake = G(z)
     c. Actualizar D para maximizar:
        log D(x_real) + log(1 - D(x_fake))

  2. Entrenar Generador (1 paso):
     a. Generar nuevo batch: z ~ p_z
     b. Actualizar G para minimizar:
        log(1 - D(G(z)))
        o equivalentemente, maximizar log D(G(z))

  3. Repetir hasta convergencia
```

**Ratio de entrenamiento:**
```
ComÃºn: k=1 (alternar D y G)
Paper original: k=5 (entrenar D mÃ¡s frecuentemente)

Por quÃ©: Evitar que G mejore demasiado rÃ¡pido
y "engaÃ±e trivialmente" a D dÃ©bil.
```

### Problemas Comunes de GANs

**1. Mode Collapse**

```
Problema: G genera siempre el mismo output

Ejemplo:
  Se pide generar dÃ­gitos 0-9
  G solo genera "8" porque engaÃ±a bien a D

Causa: G encuentra un mÃ­nimo local

Soluciones:
  - Minibatch discrimination
  - Unrolled GAN
  - MÃºltiples discriminadores
```

**2. Vanishing Gradients**

```
Problema: D es demasiado bueno â†’ G no recibe gradientes

Cuando D(G(z)) â‰ˆ 0:
  log(1 - D(G(z))) â‰ˆ log(1) = 0
  â†’ Gradiente â‰ˆ 0
  â†’ G no aprende

SoluciÃ³n: Usar -log D(G(z)) en vez de log(1 - D(G(z)))
```

**3. Non-Convergence**

```
Problema: Entrenamiento oscila, nunca converge

Causa: No es optimizaciÃ³n, es juego adversarial

SÃ­ntomas:
  - Loss de G y D oscilan
  - Calidad de generaciÃ³n varÃ­a mucho

Soluciones:
  - Ajustar learning rates
  - Usar optimizadores mÃ¡s estables (Adam)
  - Two time-scale update rule (TTUR)
```

### Variantes de GANs

**DCGAN (Deep Convolutional GAN)**
```
Mejoras arquitectÃ³nicas:
- Usar convolutions en vez de FC layers
- BatchNorm en G y D
- ReLU en G, LeakyReLU en D
- No usar pooling, usar strided convolutions

Resultado: MÃ¡s estable, mejores imÃ¡genes
```

**Conditional GAN (cGAN)**
```
Controlar quÃ© generar:

G(z, c) â†’ genera imagen de clase c
D(x, c) â†’ verifica si x es real y de clase c

Ejemplo: "Genera un 7" â†’ G(z, c=7)
```

**Wasserstein GAN (WGAN)**
```
Mejor funciÃ³n de pÃ©rdida:

L_D = E[D(x_real)] - E[D(G(z))]
L_G = -E[D(G(z))]

Ventajas:
- MÃ¡s estable
- Loss correlaciona con calidad
- No mode collapse
```

**StyleGAN**
```
Control fino sobre estilo:
- Controlar atributos especÃ­ficos
- Mezclar estilos de diferentes imÃ¡genes
- Estado del arte en generaciÃ³n de caras
```

### MÃ©tricas de EvaluaciÃ³n

**1. Inception Score (IS)**
```
Mide calidad y diversidad

IS = exp(E[KL(p(y|x) || p(y))])

Alto IS â†’ ImÃ¡genes claras y variadas
```

**2. FrÃ©chet Inception Distance (FID)**
```
Compara distribuciones

FID = ||Î¼_real - Î¼_fake||Â² + Tr(Î£_real + Î£_fake - 2âˆš(Î£_real Î£_fake))

Bajo FID â†’ Distribuciones similares
```

**3. Visual Inspection**
```
Humanos revisan calidad

Â¿Se ven realistas?
Â¿Hay diversidad?
Â¿Hay artefactos?
```

### Aplicaciones de GANs

**GeneraciÃ³n de ImÃ¡genes:**
- Caras realistas (ThisPersonDoesNotExist)
- Arte generativo
- Super-resoluciÃ³n

**Data Augmentation:**
- Generar mÃ¡s datos de entrenamiento
- Balancear clases desbalanceadas

**Image-to-Image:**
- Style transfer
- ColorizaciÃ³n
- Inpainting (rellenar partes faltantes)

**SÃ­ntesis de Datos:**
- Generar datos mÃ©dicos sintÃ©ticos
- Privacidad (datos sintÃ©ticos vs reales)

**DetecciÃ³n de AnomalÃ­as:**
- G aprende lo "normal"
- Lo que no puede generar = anomalÃ­a

---

## ğŸ¯ Escenario

**Problema:** Generar dÃ­gitos escritos a mano sintÃ©ticos (MNIST-like)

```
Input: Vector de ruido z ~ N(0, 1)
Output: Imagen 28Ã—28 que parece un dÃ­gito real

Entrenamiento:
1. D aprende a distinguir dÃ­gitos reales vs generados
2. G aprende a generar dÃ­gitos que engaÃ±en a D
3. Eventualmente, G genera dÃ­gitos realistas
```

**Ejemplo Simplificado:**

```typescript
// Generar datos
const noise = generateNoise(100);  // Vector 100D
const fakeData = generator.forward(noise);  // 28Ã—28 imagen

// Discriminar
const probReal = discriminator.forward(realImage);  // ~0.9
const probFake = discriminator.forward(fakeData);   // ~0.1

// Entrenar
trainDiscriminator(realImages, fakeData);
trainGenerator(noise);
```

---

## ğŸ“ Instrucciones

### Parte 1: Generador

```typescript
export class Generator {
  constructor(
    inputSize: number,    // DimensiÃ³n del ruido
    outputSize: number,   // DimensiÃ³n de la salida
    hiddenSizes: number[] // Capas ocultas
  ) {
    // Inicializar capas
  }

  forward(noise: number[]): number[];

  getParameters(): number[][][];
  setParameters(params: number[][][]): void;
}
```

### Parte 2: Discriminador

```typescript
export class Discriminator {
  constructor(
    inputSize: number,
    hiddenSizes: number[]
  ) {
    // Inicializar capas
    // Output: 1 neurona (probabilidad real/fake)
  }

  forward(input: number[]): number;  // [0, 1]

  getParameters(): number[][][];
  setParameters(params: number[][][]): void;
}
```

### Parte 3: GAN Completa

```typescript
export class GAN {
  constructor(config: GANConfig) {
    // Inicializar generador y discriminador
  }

  train(
    realData: number[][],
    config: TrainingConfig
  ): TrainingHistory;

  generate(numSamples: number): number[][];

  // MÃ©tricas
  evaluateDiscriminator(
    realData: number[][],
    fakeData: number[][]
  ): {
    accuracyReal: number;
    accuracyFake: number;
    averageConfidence: number;
  };

  // DetecciÃ³n de mode collapse
  detectModeCollapse(
    generatedSamples: number[][]
  ): {
    collapsed: boolean;
    diversity: number;
  };
}
```

### Parte 4: Utilidades

```typescript
export function generateNoise(
  size: number,
  distribution?: 'normal' | 'uniform'
): number[];

export function visualizeProgress(
  history: TrainingHistory
): void;

export function interpolate(
  z1: number[],
  z2: number[],
  steps: number
): number[][];
```

---

## âœ… Resultado Esperado

1. âœ… Generador que crea datos desde ruido
2. âœ… Discriminador que clasifica real/fake
3. âœ… Entrenamiento adversarial completo
4. âœ… DetecciÃ³n de mode collapse
5. âœ… InterpolaciÃ³n en espacio latente
6. âœ… MÃ©tricas de evaluaciÃ³n

---

## ğŸ§ª Tests

```bash
npm test 17-gans-generativos
```

---

## ğŸ’¡ Consejos

1. **Learning Rates:** Discriminador mÃ¡s alto que generador (ej. 0.0002 vs 0.0001)
2. **Label Smoothing:** Usar 0.9 en vez de 1.0 para datos reales
3. **Noisy Labels:** Ocasionalmente invertir labels (~5%)
4. **Architecture:** G y D de complejidad similar
5. **Activation:** LeakyReLU para evitar dying ReLU
6. **Batch Normalization:** Excepto en output de G y input de D
7. **Patience:** GANs tardan mucho en converger

---

## ğŸ“Š MatemÃ¡ticas Detalladas

**Gradientes del Discriminador:**

```
âˆ‚L_D/âˆ‚Î¸_D = -1/m Î£[âˆ‚log D(x_i)/âˆ‚Î¸_D + âˆ‚log(1-D(G(z_i)))/âˆ‚Î¸_D]

Backprop normal, dos tÃ©rminos:
1. Clasificar correctamente datos reales
2. Clasificar correctamente datos falsos
```

**Gradientes del Generador:**

```
âˆ‚L_G/âˆ‚Î¸_G = -1/m Î£[âˆ‚log D(G(z_i))/âˆ‚Î¸_G]

Chain rule:
= -1/m Î£[(1/D(G(z_i))) Ã— âˆ‚D(G(z_i))/âˆ‚G(z_i) Ã— âˆ‚G(z_i)/âˆ‚Î¸_G]

Requiere backprop a travÃ©s del discriminador
```

**Optimal Discriminator (dado G fijo):**

```
D*(x) = p_data(x) / (p_data(x) + p_g(x))

En equilibrio (p_data = p_g):
D*(x) = 1/2  (no puede distinguir)
```

**Convergencia teÃ³rica:**

```
Si G y D tienen capacidad infinita y suficiente tiempo:

p_g â†’ p_data
D(x) â†’ 1/2 para todo x

En prÃ¡ctica: Nunca alcanzamos equilibrio perfecto
```

---

## ğŸ” Debugging GANs

**D loss â†’ 0, G loss â†’ âˆ:**
```
D es demasiado bueno
â†’ Reducir learning rate de D
â†’ Entrenar G mÃ¡s veces por iteraciÃ³n
```

**G loss â†’ 0, D loss â†’ âˆ:**
```
G es demasiado bueno (raro)
â†’ Aumentar learning rate de D
â†’ Mejorar arquitectura de D
```

**Ambos loss oscilan:**
```
Normal en GANs
â†’ Monitorear calidad visual
â†’ No solo mirar loss
```

**Outputs todos iguales:**
```
Mode collapse
â†’ Minibatch discrimination
â†’ Aumentar diversidad del ruido
```

---

## ğŸ“š Recursos

- [Generative Adversarial Networks (Paper Original)](https://arxiv.org/abs/1406.2661)
- [DCGAN](https://arxiv.org/abs/1511.06434)
- [GAN Training Tips](https://github.com/soumith/ganhacks)
- [The GAN Zoo](https://github.com/hindupuravinash/the-gan-zoo)

---

**Â¡Comienza implementando el generador en `gan.ts`!** ğŸ¨
