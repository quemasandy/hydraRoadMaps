# Ejercicio 13: CNN para Visi√≥n

**Objetivo:** Implementar Convolutional Neural Networks (CNN) desde cero, entendiendo convoluciones, pooling y arquitecturas para visi√≥n por computadora.

## üìñ Teor√≠a

### ¬øQu√© es una CNN?

**Red neuronal especializada para procesar datos con estructura de grilla** (im√°genes, audio, video).

**Problema que resuelven:**
- Redes densas (fully-connected) necesitan millones de par√°metros para im√°genes
- Pierden informaci√≥n espacial
- No explotan patrones locales repetitivos

**Ejemplo:**
```
Imagen 28√ó28 ‚Üí Fully Connected (100 neuronas) = 28√ó28√ó100 = 78,400 par√°metros
Imagen 28√ó28 ‚Üí Conv (10 filtros 3√ó3) = 3√ó3√ó10 = 90 par√°metros
```

**¬°870x menos par√°metros con CNN!**

### Operaci√≥n de Convoluci√≥n

**Deslizar un filtro sobre la imagen** para detectar patrones locales.

**Matem√°tica:**
```
(I * K)[i,j] = Œ£Œ£ I[i+m, j+n] √ó K[m,n]
              m,n

donde:
- I: Imagen de entrada
- K: Kernel/filtro
- *: Operador de convoluci√≥n (no multiplicaci√≥n)
```

**Ejemplo 2D:**
```
Imagen (5√ó5):              Kernel (3√ó3):
1  2  3  4  5              1  0 -1
6  7  8  9  10       *     1  0 -1  =  ?
11 12 13 14 15             1  0 -1
16 17 18 19 20
21 22 23 24 25

C√°lculo en posici√≥n (1,1):
(1√ó1 + 2√ó0 + 3√ó-1) +
(6√ó1 + 7√ó0 + 8√ó-1) +
(11√ó1 + 12√ó0 + 13√ó-1) = -6

Feature Map:
-6  -6  -6
-6  -6  -6
-6  -6  -6
```

**Interpretaci√≥n:**
Este kernel detecta **bordes verticales** (diferencia entre izquierda y derecha).

### Par√°metros de Convoluci√≥n

**1. Padding (Relleno):**
```
Valid (sin padding):
Input: n√ón
Output: (n-k+1)√ó(n-k+1)  ‚Üê la imagen se reduce

Same (con padding):
Padding = (k-1)/2
Output: n√ón  ‚Üê mantiene tama√±o
```

**2. Stride (Paso):**
```
Stride = 1: Mover filtro 1 pixel a la vez
Stride = 2: Mover filtro 2 pixels (subsampling)

Output size = ‚åä(n + 2p - k)/s‚åã + 1
donde:
- n: tama√±o input
- k: tama√±o kernel
- p: padding
- s: stride
```

**3. Channels (Canales):**
```
RGB image: 3 canales (R, G, B)
Kernel: debe tener misma profundidad que input
Output: n√∫mero de kernels = n√∫mero de feature maps
```

### Tipos de Kernels Comunes

**Edge Detection (Detecci√≥n de bordes):**
```
Horizontal:          Vertical:
 1  1  1             1  0 -1
 0  0  0             1  0 -1
-1 -1 -1             1  0 -1
```

**Sharpen (Afilar):**
```
 0 -1  0
-1  5 -1
 0 -1  0
```

**Blur (Desenfoque):**
```
1/9 √ó [1 1 1]
      [1 1 1]
      [1 1 1]
```

### Pooling Layers

**Reducir dimensionalidad espacial** preservando informaci√≥n importante.

**Max Pooling:**
```
Input (4√ó4):          Max Pool 2√ó2, stride=2:
1  2  3  4
5  6  7  8       ‚Üí    6  8
9  10 11 12           14 16
13 14 15 16

Toma el m√°ximo de cada regi√≥n 2√ó2
```

**Average Pooling:**
```
Mismo proceso pero promediando en vez de max
```

**Ventajas:**
- Reduce par√°metros y c√≥mputo
- Invarianza a peque√±as traslaciones
- Previene overfitting
- Extrae features dominantes

**Max vs Average:**
- **Max:** Mejor para detectar features (si feature presente, max es alto)
- **Average:** M√°s suave, preserva informaci√≥n de fondo

### Arquitectura CNN T√≠pica

```
Input Image (28√ó28√ó1)
    ‚Üì
Conv Layer 1 (10 filters 3√ó3) ‚Üí (26√ó26√ó10)
    ‚Üì ReLU
MaxPool (2√ó2) ‚Üí (13√ó13√ó10)
    ‚Üì
Conv Layer 2 (20 filters 3√ó3) ‚Üí (11√ó11√ó20)
    ‚Üì ReLU
MaxPool (2√ó2) ‚Üí (5√ó5√ó20) = 500 features
    ‚Üì
Flatten ‚Üí (500)
    ‚Üì
Dense (50) ‚Üí ReLU
    ‚Üì
Dense (10) ‚Üí Softmax
    ‚Üì
Output (10 classes)
```

**Patr√≥n:**
```
CONV ‚Üí ReLU ‚Üí POOL ‚Üí CONV ‚Üí ReLU ‚Üí POOL ‚Üí FC ‚Üí ReLU ‚Üí FC
```

### ¬øPor qu√© funcionan las CNN?

**1. Local Connectivity (Conexiones Locales):**
- Cada neurona solo mira ventana peque√±a (receptive field)
- Patrones visuales son locales (bordes, texturas)

**2. Parameter Sharing (Compartir Par√°metros):**
- Mismo filtro se usa en toda la imagen
- Detector de borde √∫til arriba tambi√©n √∫til abajo

**3. Translation Invariance (Invarianza a traslaci√≥n):**
- Reconoce gato independientemente de posici√≥n
- Pooling ayuda con esto

**4. Hierarchical Features (Features Jer√°rquicas):**
```
Capa 1: Bordes, colores
Capa 2: Texturas, partes simples
Capa 3: Partes de objetos
Capa 4: Objetos completos
```

### C√°lculo del Receptive Field

**Campo receptivo:** Regi√≥n de la imagen original que afecta a una neurona.

```
Layer 1: RF = 3√ó3  (kernel size)
Layer 2: RF = 5√ó5  (cada pixel ve 3√ó3, y estos ven 3√ó3)
Layer 3: RF = 7√ó7  (crece con profundidad)

Formula general:
RF_{l+1} = RF_l + (k-1) √ó stride_product
```

---

## üéØ Escenario

**Dataset:** Clasificaci√≥n de d√≠gitos manuscritos (MNIST simplificado)

```
Input: Imagen 8√ó8 (64 p√≠xeles)
Output: D√≠gito (0-9)

Ejemplo:
. . # # # . .
. # . . . # .
. . . . # # .
. . . # . . .
. . # . . . .
. # # # # # .
. . . . . . .

‚Üí Predicci√≥n: "5"
```

---

## üìù Instrucciones

### Parte 1: Operaciones de Convoluci√≥n

```typescript
export function convolve2D(
  input: number[][],
  kernel: number[][],
  stride?: number,
  padding?: number
): number[][];

export function correlate2D(
  input: number[][],
  kernel: number[][],
  stride?: number,
  padding?: number
): number[][];

export function padImage(
  image: number[][],
  padding: number,
  value?: number
): number[][];

export function computeOutputSize(
  inputSize: number,
  kernelSize: number,
  stride: number,
  padding: number
): number;
```

### Parte 2: Pooling Operations

```typescript
export function maxPool2D(
  input: number[][],
  poolSize: number,
  stride?: number
): number[][];

export function avgPool2D(
  input: number[][],
  poolSize: number,
  stride?: number
): number[][];

export function globalMaxPool2D(input: number[][]): number;
export function globalAvgPool2D(input: number[][]): number;
```

### Parte 3: Convolutional Layer

```typescript
export interface ConvLayerConfig {
  numFilters: number;
  kernelSize: number;
  stride?: number;
  padding?: number;
  activation?: 'relu' | 'sigmoid';
}

export class ConvLayer {
  constructor(
    inputChannels: number,
    config: ConvLayerConfig
  ) {
    // Inicializar filtros (kernels)
  }

  forward(input: number[][][]): number[][][] {
    // Aplicar convoluci√≥n con todos los filtros
  }

  getFilters(): number[][][][];
}
```

### Parte 4: Arquitectura CNN Simple

```typescript
export interface SimpleCNNConfig {
  inputSize: number;
  numClasses: number;
}

export class SimpleCNN {
  private conv1: ConvLayer;
  private conv2: ConvLayer;
  // ... fully connected layers

  constructor(config: SimpleCNNConfig) {
    // Construir arquitectura
  }

  forward(input: number[][]): number[];
  predict(input: number[][]): number;
  predictProba(input: number[][]): number[];
}
```

---

## ‚úÖ Resultado Esperado

1. ‚úÖ Operaci√≥n de convoluci√≥n 2D desde cero
2. ‚úÖ Padding y stride configurables
3. ‚úÖ Max pooling y average pooling
4. ‚úÖ Capa convolucional con m√∫ltiples filtros
5. ‚úÖ CNN simple completa
6. ‚úÖ Visualizar feature maps
7. ‚úÖ Detectar bordes en im√°genes

---

## üß™ Tests

```bash
npm test 13-cnn-vision
```

---

## üí° Consejos

1. **Kernel size:** 3√ó3 es est√°ndar (VGG), 5√ó5 para inicio (LeNet)
2. **Padding:** "same" para mantener tama√±o, "valid" para reducir
3. **Stride:** 1 es com√∫n en CONV, 2 en POOL
4. **Channels:** Aumentan con profundidad (16 ‚Üí 32 ‚Üí 64 ‚Üí 128)
5. **Activaci√≥n:** ReLU despu√©s de cada CONV
6. **Pooling:** Max pool 2√ó2 stride 2 es est√°ndar
7. **Arquitectura:** Empezar simple (2 CONV + 2 FC)

---

## üìä Matem√°ticas Detalladas

**Convoluci√≥n 2D (un canal):**
```
Output[i,j] = Œ£ Œ£ Input[i√ós + m, j√ós + n] √ó Kernel[m,n]
             m=0 n=0
             hasta k-1

donde:
- i,j: posici√≥n en output
- s: stride
- m,n: posici√≥n en kernel
- k: tama√±o kernel
```

**Convoluci√≥n multichannel:**
```
Para cada filtro f:
  Output[i,j,f] = Œ£ Œ£ Œ£ Input[i,j,c] √ó Kernel[m,n,c,f]
                  c m n

donde c recorre todos los canales de entrada
```

**Dimensiones:**
```
Input:   (H, W, C_in)
Kernel:  (K, K, C_in, C_out)
Output:  (H', W', C_out)

donde:
H' = (H + 2p - K) / s + 1
W' = (W + 2p - K) / s + 1
```

---

## üìö Recursos

- [CNN Explainer - Interactive](https://poloclub.github.io/cnn-explainer/)
- [CS231n: Convolutional Networks](http://cs231n.github.io/convolutional-networks/)
- [Understanding Convolutions](https://colah.github.io/posts/2014-07-Understanding-Convolutions/)
- [LeNet-5 Paper (1998)](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)

---

**¬°Comienza implementando la operaci√≥n de convoluci√≥n en `cnn.ts`!** üñºÔ∏è
