# Ejercicio 05: Gradient Descent

**Objetivo:** Implementar algoritmos de optimizaci√≥n basados en gradiente descendente, fundamentales para entrenar modelos de Machine Learning.

## üìñ Teor√≠a

### ¬øQu√© es Gradient Descent?

Gradient Descent es el algoritmo de optimizaci√≥n m√°s importante en Machine Learning. Se usa para:
- **Entrenar redes neuronales**: Ajustar pesos para minimizar el error
- **Regresi√≥n lineal**: Encontrar la l√≠nea que mejor ajusta los datos
- **Regresi√≥n log√≠stica**: Optimizar la funci√≥n de clasificaci√≥n
- **Cualquier funci√≥n diferenciable**: Encontrar m√≠nimos locales/globales

### El Problema de Optimizaci√≥n

Queremos encontrar `Œ∏` que minimice una funci√≥n de costo `J(Œ∏)`:
```
Œ∏* = argmin J(Œ∏)
```

Ejemplo en regresi√≥n lineal:
```
J(Œ∏) = (1/2m) Œ£(hŒ∏(xi) - yi)¬≤
donde hŒ∏(x) = Œ∏0 + Œ∏1*x
```

### Conceptos Fundamentales

#### 1. **El Gradiente**

El gradiente `‚àáJ(Œ∏)` es un vector de derivadas parciales:
```
‚àáJ(Œ∏) = [‚àÇJ/‚àÇŒ∏0, ‚àÇJ/‚àÇŒ∏1, ..., ‚àÇJ/‚àÇŒ∏n]
```

Propiedades:
- Apunta en la direcci√≥n de **mayor crecimiento**
- La direcci√≥n opuesta `-‚àáJ(Œ∏)` es la de **mayor decrecimiento**
- Su magnitud indica qu√© tan empinada es la funci√≥n

#### 2. **Batch Gradient Descent**

Actualiza los par√°metros usando **todos** los datos:
```
Œ∏ = Œ∏ - Œ± √ó ‚àáJ(Œ∏)
```

Donde:
- `Œ±` (alpha) es el **learning rate** (tasa de aprendizaje)
- `‚àáJ(Œ∏)` es el gradiente calculado con todos los datos

**Ventajas:**
- Convergencia suave y estable
- Garantiza convergencia para funciones convexas

**Desventajas:**
- Lento con datasets grandes
- Costoso computacionalmente

#### 3. **Stochastic Gradient Descent (SGD)**

Actualiza los par√°metros usando **un solo** ejemplo:
```
Para cada ejemplo (xi, yi):
  Œ∏ = Œ∏ - Œ± √ó ‚àáJ(Œ∏; xi, yi)
```

**Ventajas:**
- Mucho m√°s r√°pido
- Puede escapar de m√≠nimos locales (por el ruido)
- Actualiza frecuentemente

**Desventajas:**
- Convergencia ruidosa
- Puede oscilar alrededor del m√≠nimo

#### 4. **Mini-Batch Gradient Descent**

Compromiso entre Batch y SGD, usa un **subconjunto** de datos:
```
Para cada batch de tama√±o b:
  Œ∏ = Œ∏ - Œ± √ó ‚àáJ(Œ∏; batch)
```

**Ventajas:**
- Balance entre velocidad y estabilidad
- Aprovecha paralelizaci√≥n (GPUs)
- Es el m√°s usado en pr√°ctica

#### 5. **Learning Rate (Œ±)**

El learning rate controla el tama√±o del paso:
```
- Muy peque√±o: Convergencia lenta
- Muy grande: Puede diverger
- √ìptimo: Convergencia r√°pida y estable
```

Estrategias:
- **Constante**: Œ± fijo
- **Decaimiento**: Œ± disminuye con el tiempo
- **Adaptativo**: Ajusta Œ± autom√°ticamente (Adam, RMSprop)

#### 6. **Optimizadores Avanzados**

**Momentum:**
```
v = Œ≤ √ó v + ‚àáJ(Œ∏)
Œ∏ = Œ∏ - Œ± √ó v
```
- Acelera convergencia
- Reduce oscilaciones

**RMSprop:**
```
s = Œ≤ √ó s + (1-Œ≤) √ó (‚àáJ(Œ∏))¬≤
Œ∏ = Œ∏ - Œ± √ó ‚àáJ(Œ∏) / ‚àö(s + Œµ)
```
- Adapta learning rate por par√°metro

**Adam (Adaptive Moment Estimation):**
```
m = Œ≤1 √ó m + (1-Œ≤1) √ó ‚àáJ(Œ∏)
v = Œ≤2 √ó v + (1-Œ≤2) √ó (‚àáJ(Œ∏))¬≤
Œ∏ = Œ∏ - Œ± √ó m / (‚àöv + Œµ)
```
- Combina Momentum y RMSprop
- El m√°s popular actualmente

---

## üéØ Escenario

Tienes datos de precios de casas y quieres predecir el precio basado en el tama√±o:
```
Datos: [(50m¬≤, $100k), (80m¬≤, $160k), (100m¬≤, $200k)]
Modelo: precio = Œ∏0 + Œ∏1 √ó tama√±o
```

Objetivo: Encontrar Œ∏0 y Œ∏1 que minimicen el error:
```
J(Œ∏) = (1/2m) Œ£(Œ∏0 + Œ∏1√óxi - yi)¬≤
```

Gradiente:
```
‚àÇJ/‚àÇŒ∏0 = (1/m) Œ£(Œ∏0 + Œ∏1√óxi - yi)
‚àÇJ/‚àÇŒ∏1 = (1/m) Œ£((Œ∏0 + Œ∏1√óxi - yi) √ó xi)
```

---

## üìù Instrucciones

### Parte 1: Batch Gradient Descent

Implementa el algoritmo b√°sico:

```typescript
export interface GDParams {
  learningRate: number;
  iterations: number;
  tolerance?: number;
}

export interface GDResult {
  theta: number[];
  costs: number[];
  iterations: number;
}

export function gradientDescent(
  X: number[][],
  y: number[],
  params: GDParams
): GDResult {
  // Tu c√≥digo aqu√≠
  // 1. Inicializar theta con ceros
  // 2. Para cada iteraci√≥n:
  //    - Calcular predicciones
  //    - Calcular gradiente
  //    - Actualizar theta
  //    - Guardar costo
  //    - Verificar convergencia
}

// Ejemplo de uso:
const X = [[1, 50], [1, 80], [1, 100]]; // [bias, tama√±o]
const y = [100, 160, 200];
const result = gradientDescent(X, y, {
  learningRate: 0.01,
  iterations: 1000
});
console.log('Par√°metros:', result.theta);
```

### Parte 2: Stochastic Gradient Descent

Implementa SGD:

```typescript
export function stochasticGradientDescent(
  X: number[][],
  y: number[],
  params: GDParams & { epochs: number }
): GDResult {
  // Tu c√≥digo aqu√≠
  // 1. Para cada √©poca:
  //    - Mezclar los datos
  //    - Para cada ejemplo:
  //      - Calcular gradiente con un solo ejemplo
  //      - Actualizar theta
  //    - Calcular costo total de la √©poca
}

// Ejemplo de uso:
const result = stochasticGradientDescent(X, y, {
  learningRate: 0.01,
  iterations: 100,
  epochs: 10
});
```

### Parte 3: Mini-Batch Gradient Descent

Implementa Mini-Batch GD:

```typescript
export function miniBatchGradientDescent(
  X: number[][],
  y: number[],
  params: GDParams & { batchSize: number }
): GDResult {
  // Tu c√≥digo aqu√≠
  // 1. Para cada √©poca:
  //    - Dividir datos en batches
  //    - Para cada batch:
  //      - Calcular gradiente con el batch
  //      - Actualizar theta
}

// Ejemplo de uso:
const result = miniBatchGradientDescent(X, y, {
  learningRate: 0.01,
  iterations: 100,
  batchSize: 32
});
```

### Parte 4: Momentum

Implementa Momentum:

```typescript
export function gradientDescentWithMomentum(
  X: number[][],
  y: number[],
  params: GDParams & { momentum: number }
): GDResult {
  // Tu c√≥digo aqu√≠
  // 1. Inicializar velocidad v = 0
  // 2. Para cada iteraci√≥n:
  //    - Calcular gradiente
  //    - v = Œ≤ √ó v + ‚àáJ(Œ∏)
  //    - Œ∏ = Œ∏ - Œ± √ó v
}

// Ejemplo de uso:
const result = gradientDescentWithMomentum(X, y, {
  learningRate: 0.01,
  iterations: 1000,
  momentum: 0.9
});
```

### Parte 5: Adam Optimizer

Implementa Adam:

```typescript
export interface AdamParams {
  learningRate: number;
  beta1?: number;
  beta2?: number;
  epsilon?: number;
  iterations: number;
}

export function adam(
  X: number[][],
  y: number[],
  params: AdamParams
): GDResult {
  // Tu c√≥digo aqu√≠
  // 1. Inicializar m = 0, v = 0
  // 2. Para cada iteraci√≥n t:
  //    - Calcular gradiente g
  //    - m = Œ≤1√óm + (1-Œ≤1)√óg
  //    - v = Œ≤2√óv + (1-Œ≤2)√óg¬≤
  //    - mÃÇ = m / (1-Œ≤1^t) (bias correction)
  //    - vÃÇ = v / (1-Œ≤2^t)
  //    - Œ∏ = Œ∏ - Œ± √ó mÃÇ / (‚àövÃÇ + Œµ)
}

// Ejemplo de uso:
const result = adam(X, y, {
  learningRate: 0.01,
  beta1: 0.9,
  beta2: 0.999,
  epsilon: 1e-8,
  iterations: 1000
});
```

### Parte 6: Funciones de Utilidad

Implementa funciones auxiliares:

```typescript
export function predict(X: number[][], theta: number[]): number[] {
  // Tu c√≥digo aqu√≠
  // Calcula y = X √ó Œ∏
}

export function computeCost(
  X: number[][],
  y: number[],
  theta: number[]
): number {
  // Tu c√≥digo aqu√≠
  // J(Œ∏) = (1/2m) Œ£(hŒ∏(xi) - yi)¬≤
}

export function computeGradient(
  X: number[][],
  y: number[],
  theta: number[]
): number[] {
  // Tu c√≥digo aqu√≠
  // ‚àáJ(Œ∏) = (1/m) √ó X^T √ó (X√óŒ∏ - y)
}

export function shuffle<T>(array: T[]): T[] {
  // Fisher-Yates shuffle
}
```

---

## ‚úÖ Resultado Esperado

Al finalizar, deber√≠as poder:

1. ‚úÖ Implementar Batch, SGD y Mini-Batch Gradient Descent
2. ‚úÖ Calcular gradientes correctamente
3. ‚úÖ Implementar optimizadores avanzados (Momentum, Adam)
4. ‚úÖ Entender el impacto del learning rate
5. ‚úÖ Visualizar la convergencia del costo
6. ‚úÖ Comparar diferentes optimizadores

---

## üß™ Tests

Ejecuta los tests para verificar tu implementaci√≥n:

```bash
npm test 05-gradient-descent
```

Los tests verificar√°n:
- Convergencia a valores correctos
- Reducci√≥n monot√≥nica del costo (Batch GD)
- Gradientes calculados correctamente
- Optimizadores convergen m√°s r√°pido
- Manejo de diferentes learning rates

---

## üí° Consejos

1. **Normaliza features**: X con media 0 y std 1 converge m√°s r√°pido
2. **Learning rate schedule**: Reduce Œ± con el tiempo
3. **Inicializaci√≥n**: Empieza con theta = 0 o valores peque√±os aleatorios
4. **Convergencia**: Det√©n cuando |ŒîJ| < tolerance
5. **Vectorizaci√≥n**: Usa operaciones matriciales en lugar de loops

---

## üéì Conceptos Clave

- **Convexidad**: Funciones convexas tienen un solo m√≠nimo global
- **Saddle points**: Puntos donde el gradiente es 0 pero no es m√≠nimo
- **Vanishing gradients**: Gradientes muy peque√±os ‚Üí aprendizaje lento
- **Exploding gradients**: Gradientes muy grandes ‚Üí divergencia
- **Learning rate decay**: Œ±(t) = Œ±0 / (1 + decay √ó t)
- **Gradient clipping**: Limita la magnitud del gradiente

---

## üìä Comparaci√≥n de Optimizadores

| Algoritmo | Velocidad | Memoria | Convergencia |
|-----------|-----------|---------|--------------|
| Batch GD  | Lenta     | Baja    | Suave        |
| SGD       | R√°pida    | Baja    | Ruidosa      |
| Mini-Batch| Media     | Media   | Balanceada   |
| Momentum  | R√°pida    | Media   | Suave        |
| Adam      | Muy r√°pida| Alta    | Muy suave    |

**Recomendaci√≥n:** Usa Adam para la mayor√≠a de problemas.

---

## üìö Recursos

- [Gradient Descent - Andrew Ng](https://www.coursera.org/learn/machine-learning)
- [An Overview of Gradient Descent Optimization Algorithms](https://ruder.io/optimizing-gradient-descent/)
- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
- [Why Momentum Works](https://distill.pub/2017/momentum/)

---

**¬°Comienza implementando en `gradient-descent.ts`!** üöÄ
